import spacy
import re
from spacy.matcher import PhraseMatcher
import pymorphy3




#–•—Ä–µ–Ω—å –∫–æ—Ç–æ—Ä–∞—è –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –≤ –µ–¥ —á–∏—Å–ª–æ –∏–º –ø–∞–¥–µ–∂–∞ —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã (–≤—Å–ø–æ–º–∏–Ω–∞–µ–º —É—Ä–æ–∫–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ 4 –∫–ª–∞—Å—Å)
def to_nominative_singular(word):
    word = word.split(" ")
    morph = pymorphy3.MorphAnalyzer() # –£–º–Ω—ã–π —á–µ–ª –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ø–∞–¥–µ–∂—ã
    for i, w in enumerate(word):
        word[i] = morph.parse(w)[0].normal_form.capitalize() # –ü–µ—Ä–µ–≤–æ–¥–∏–º
    return " ".join(word)

# NLP –º–æ–¥–µ–ª–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
nlp_en = spacy.load("en_core_web_sm")
nlp_ru = spacy.load("ru_core_news_sm")

# –•—Ä–µ–Ω—å —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ –∏–∫–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ
work_form_matcher_en = PhraseMatcher(nlp_en.vocab)
work_form_matcher_ru = PhraseMatcher(nlp_ru.vocab)

work_forms = ["remote", "hybrid", "office", "—É–¥–∞–ª—ë–Ω–∫–∞", "–æ—Ñ–∏—Å", "–≥–∏–±—Ä–∏–¥"]

# Add patterns to both matchers
for matcher, nlp in [(work_form_matcher_en, nlp_en), (work_form_matcher_ru, nlp_ru)]:
    patterns = [nlp(text) for text in work_forms]
    matcher.add("WORK_FORM", patterns)


# PRE-BUILT VACANCY MATCHERS (FIXED)
vacancy_matcher_en = PhraseMatcher(nlp_en.vocab)
vacancy_matcher_ru = PhraseMatcher(nlp_ru.vocab)

# Enhanced vacancy keywords (added "—Å—Ç–∞–∂—ë—Ä")
vacancy_keywords = {
    'en': ["hiring", "apply now", "job opening", "vacancy", "position", "opportunity"],
    'ru': ["–∏—â–µ–º", "—Ç—Ä–µ–±—É–µ—Ç—Å—è", "–≤–∞–∫–∞–Ω—Å–∏—è", "–Ω–∞–±–æ—Ä", "—Å—Ç–∞–∂—ë—Ä", "—Ä–∞–±–æ—Ç–∞", "—Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ"]
}

# Create patterns for vacancy detection
patterns_en = [nlp_en(text) for text in vacancy_keywords['en']]
patterns_ru = [nlp_ru(text) for text in vacancy_keywords['ru']]
vacancy_matcher_en.add("VACANCY", patterns_en)
vacancy_matcher_ru.add("VACANCY", patterns_ru)

# Add custom patterns for job titles
job_title_patterns = [
    {"label": "OCCUPATION", "pattern": [{"LOWER": "—Å—Ç–∞–∂—ë—Ä"}, {"LOWER": "data"}, {"LOWER": "science"}]},
    {"label": "OCCUPATION", "pattern": [{"LOWER": "data"}, {"LOWER": "scientist"}]},
    {"label": "OCCUPATION", "pattern": [{"LOWER": "–º–µ–Ω–µ–¥–∂–µ—Ä"}]},
    {"label": "OCCUPATION", "pattern": [{"LOWER": "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫"}]}
]

# Add patterns to both pipelines
for nlp in [nlp_en, nlp_ru]:
    ruler = nlp.add_pipe("entity_ruler")
    ruler.add_patterns(job_title_patterns)


# FIXED VACANCY DETECTION
def is_vacancy(doc):
    """Check if document contains vacancy keywords"""
    if doc.lang_ == "en":
        matches = vacancy_matcher_en(doc)
    else:  # Assume Russian
        matches = vacancy_matcher_ru(doc)
    return len(matches) > 0


def extract_job_title(doc):
    # First look for OCCUPATION entities
    for ent in doc.ents:
        if ent.label_ == "OCCUPATION":
            return ent.text.capitalize()

    # Look for keywords in the text
    job_keywords = ["developer", "–º–µ–Ω–µ–¥–∂–µ—Ä", "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç", "—Å—Ç–∞–∂—ë—Ä", "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫", "scientist", "–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥", "–¥–∏–∑–∞–π–Ω–µ—Ä"]
    for token in doc:
        if token.text.lower() in job_keywords:
            # Get surrounding text (3 words before and after)
            start = max(0, token.i)
            end = min(len(doc), token.i + 4)
            return doc[start:end].text.capitalize()

    # Fallback to first noun phrase (English only)
    if doc.lang_ == "en":
        for chunk in doc.noun_chunks:
            return chunk.text.capitalize()

    if ("—Å—Ç–∞–∂–∏—Ä–æ–≤–∫" in doc.text or "C—Ç–∞–∂–∏—Ä–æ–≤–∫" in doc.text):
        return "–°—Ç–∞–∂—ë—Ä"

    return None


def extract_company(doc):
    companies = [
        '–ê—Ç–æ–º–¥–∞—Ç–∞-–ò–Ω–Ω–æ–ø–æ–ª–∏—Å',
        '–ò–Ω–Ω–æ–ø–æ–ª–∏—Å –î–µ–≤–µ–ª–æ–ø–º–µ–Ω—Ç',
        '–ê–ô–í–ò–°',
        '–ê–π–î–∏ –†–µ—à–µ–Ω–∏—è',
        '–ê–π–¢–∏–°—Ñ–µ—Ä–∞',
        '–ê–π –°–∏ –°–ø–µ–π—Å',
        '–ê–π–°–∏–≠–ª –°–∏—Å—Ç–µ–º–Ω—ã–µ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ê–π–°–∏–≠–ª –°–æ—Ñ—Ç',
        '–ê–π–°–∏–≠–ª –¢–µ—Ö–Ω–æ',
        '–ê–π–°–∏–≠–ª –≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫—Å',
        '–ê–π-–¢–µ–∫–æ –ù–æ–≤—ã–µ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ê–π–¢—É–ë–∏',
        '–ê–∫ –ë–∞—Ä—Å –¶–∏—Ñ—Ä–æ–≤—ã–µ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ê–ª–ª–æ–∫–∞ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞',
        '–ê-–¢–†–≠–ö–ï–†',
        '–ë–∞—Å—Ç—Ä–∏–º',
        '–ë–∞—Ç–∞—Ä–µ–æ–Ω',
        '–ë–∏ –ü–∏ –≠–º –≠–Ω–≤–∞–π—Ä–æ–Ω–º–µ–Ω—Ç',
        '–ë–∏–ø–∏—É–º',
        '–ë–†–ò–û–õ–û–î–ñ–ò',
        '–í–∞–π—Å –°–∏—Ç–∏ –°–∏—Å—Ç–µ–º—Å',
        '–í–∞–ª–∞–¥–æ—Ä—É—Å –°–æ—Ñ—Ç',
        '–í–µ–π–≤–∑ –ò–Ω–Ω–æ–ø–æ–ª–∏—Å',
        '–í–∏–∑–∏–æ–ª–æ–¥–∂–∏ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–í–†–ú –ì—Ä—É–ø–ø',
        '–í–§-–ò–Ω–Ω–æ',
        '–ì–µ–º–æ—Å–∫–∞–Ω',
        '–ì—Ä–æ—Å—Å –î–∏–¥–∂–∏—Ç–∞–ª',
        '–î–∂–∞–π–≤–∏—Å',
        '–î–∂–µ—Ç—Å',
        '–î–∂–∏–î–∏–°–∏ –°–µ—Ä–≤–∏—Å–µ–∑',
        '–î–∏–¥–∂–∏—Ç–∞–ª–ë–∏–∑–§—ç–∫—Ç–æ—Ä–∏',
        '–î–ò–û–ù –°–û–§–¢',
        '–î—É–≥–ª–∏—Å-–°–ê–ê–°',
        '–ï–¥–∏–Ω—ã–µ –±–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ï–û–†–ê –î–ê–¢–ê –õ–ê–ë',
        '–ó–µ–¥ –°–æ—Ñ—Ç –õ–∞–±—Å',
        '–ó–µ–Ω–ö–∞—Ä',
        '–ó–∏–Ω–≥',
        '–ò–í–ö–°',
        '–ò–Ω–¥–∞—Å–æ—Ñ—Ç –ò–Ω–Ω–æ–≤–∞—Ü–∏–∏',
        '–ò–Ω–Ω–æ–ì–µ–æ–¢–µ—Ö',
        '–ò–Ω–Ω–æ–¥–∞—Ç–∞',
        '–ò–Ω–Ω–æ–∫–æ–¥',
        '–ò–Ω–Ω–æ–ø–æ–ª–∏—Å 2023',
        '–ò–Ω–Ω–æ—Å–æ—Ñ—Ç',
        '–ò–Ω–Ω–æ—Å—Ç–µ–π–¥–∂ –¶–†',
        '–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –¢–µ—Ö–Ω–æ–ª–æ–¥–∂–∏—Å',
        '–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–∏–¥–µ–æ–∞–Ω–∞–ª–∏—Ç–∏–∫–∞',
        '–ò–¢ –ò–ö–° 5 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ò—Ç–µ—Ä—Ä–∞-–ú–æ–¥—É–ª–∏',
        '–ò–¶–° –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞',
        '–ö–∞—Å–∞–Ω–¥—Ä–∞ –ì—Ä—É–ø',
        '–ö–æ–Ω—Ç—É—Ä –ò–Ω–Ω–æ–≤–∞—Ü–∏–∏',
        '–ö-–ü—Ä–æ–µ–∫—Ç—ã',
        '–ö—å—é–º–∏ –ê–π–¢–∏',
        '–õ–µ–º–æ–Ω –¢–µ—Ö–Ω–æ–ª–æ–¥–∂–∏—Å –ì—Ä—É–ø',
        '–ú–∞–≥–Ω–∏—Ç –ò–¢ –õ–∞–±',
        '–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å-–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ú–∞—Ä—Å –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ú–í–° –ò–Ω–¥–∞—Ç–∞',
        '–ú–µ–¥–∏—Ç–µ–∫–∞ –î–∏–¥–∂–∏—Ç–∞–ª',
        '–ú–µ–¥–ú–∞—Ä–∫–µ—Ç',
        '–ú–æ–±–∏–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞',
        '–ú–æ–±–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ',
        '–ú–û–ù–ï–¢–ê –õ–ê–ë–°',
        '–ú–¢–° –õ–∞–±',
        '–ù–∞–≤–∏–∫–µ–π',
        '–ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –¶–µ–Ω—Ç—Ä –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∑–∞—Ü–∏–∏',
        '–ù–ò–•–ê–û',
        '–ù–æ–≤–æ–ì–µ–Ω',
        '–ù–æ–≤—ã–µ –æ–±–ª–∞—á–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–ù–ü–ü –°–≤—è–∑—å-–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ',
        '–û–ø—Ç–∏–º—É—Å',
        '–û—Ä–≥–Ω–µ—Ñ—Ç–µ—Ö–∏–º –ê–π–¢–∏',
        '–û–†–õ–ê–ù –î–∏–¥–∂–∏—Ç–∞–ª',
        '–û—Ç–∫—Ä—ã—Ç–∞—è –º–æ–±–∏–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞',
        '–û—É–Ω',
        '–ü–æ—É–º—É',
        '–ü–†–ú –ò–Ω–Ω–æ–ø–æ–ª–∏—Å',
        '–ü–°–ö –°–ú–ê–†–¢ –ü–ê–†–ö',
        '–†–∞–¥–∏—É—Å –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è',
        '–†–∞–π—Ö–ª–∏–Ω –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–†–∏—ç–ª—å –¶–∏—Ñ—Ä–æ–≤—ã–µ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–†–ú–î',
        '–†–æ–∞–¥–∞—Ä',
        '–†–æ–±–æ—Å–æ—Ñ—Ç',
        '–†–¢–ö –°–æ—Ñ—Ç –õ–∞–±—Å',
        '–†—É–ù–µ–¥—Ä–∞',
        '–†—É—Å–ª–∞–Ω–¥ –¢–µ—Ö',
        '–†—É—Å–¥—Ä–æ–Ω–æ–ø–æ—Ä—Ç',
        '–†–≠–î–ú–≠–î–†–û–ë–û–¢ –ò–ù–ù–û–í–ê–¶–ò–ò',
        '–†—ç–π–ª—é–∫—Å',
        '–°–∞–π–±–µ—Ä—Å–∫–µ–π–ø –∏–Ω–≤–µ—Å—Ç–º–µ–Ω—Ç',
        '–°–∞—Ñ–î–µ–∫–æ—Ä',
        '–°–≤–µ–∂–∏–µ —Ä–µ—à–µ–Ω–∏—è',
        '–°–î–° –¢–µ–ª–µ–∫–æ–º',
        '–°–∏–Ω–µ—Ä–≥–∏—è –°–æ—Ñ—Ç',
        '–°–∏—Ä–∏–Ω –ì—Ä—É–ø–ø',
        '–°–ò–°–¢–≠–ú–°–û–§–¢',
        '–°–ö–ë –ò–Ω—Ñ–æ–º–∞—Ç–∏–∫–∞',
        '–°–ú–ê–†–¢–§–ê–†–ú',
        '–°–æ—Ä–∞–º–∏—Ç—Å—É –õ–∞–±—Å',
        '–°–¢–£–î–ò–Ø –õ–ò–î–°',
        '–¢–ê-–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–¢–∞—Ç–ò–¢–Ω–µ—Ñ—Ç—å',
        '–¢–∞—Ç–ú–æ–±–∞–π–ª–ò–Ω—Ñ–æ—Ä–º –°–∏–î–∏–°–∏',
        '–¢–ì–¢ –°–µ—Ä–≤–∏—Å',
        '–¢–µ—Ö–∫—Ä–∞—É–¥ –≠–π–ê–π',
        '–¢–ò–ò–î',
        '–¢–†–ê–ö–ò–ù–°–¢–û–ö',
        '–¢—Ä–∞–Ω—Å–ø—ç—Ä–µ–Ω—Ç –¢–µ—Ö–Ω–æ–ª–æ–¥–∂–∏—Å',
        '–¢—Ä–µ–Ω–¥–ø–ª–∞—Å—Ç-–ú',
        '–£–º–Ω–∞—è –∫–∞–º–µ—Ä–∞',
        '–£–º–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è',
        '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –ò–¢ —Å–∏—Å—Ç–µ–º—ã',
        '–§–∞—Ä–º–ú–µ–¥–ü–æ–ª–∏—Å –†–¢',
        '–•–∞–π–†—É—Å',
        '–•–∞–π—Ç–µ–∫–ü–∞—Ä–∫',
        '–¶–∏—Ñ—Ä–æ–≤–æ–π –°–µ—Ä–≤–∏—Å –ü—Ä–æ–≤–∞–π–¥–µ—Ä',
        '–¶–û–ö –ù–¢–ò',
        '–≠–≤–æ—Ç—ç–∫-–ú–∏—Ä–∞–π –ì–µ–Ω–æ–º–∏–∫—Å',
        '–≠–õ–°–£–†',
        '–≠–ù–ï–†–ì–û–°–û–§–¢',
        '–≠—Ç—Ç–æ–Ω –ì—Ä—É–ø',
        '–≠—Ç—Ç–æ–Ω –ù–µ—Ñ—Ç–µ–≥–∞–∑–æ–≤—ã–µ –†–µ—à–µ–Ω–∏—è',
        '–Æ–Ω–∏—Ç–µ–ª–ª–µ—Ä-–†–¢–ò',
        'Acronis',
        'ICL Services',
        'ICL Soft',
        'Uniteller',
        '–≠—Ç—Ç–æ–Ω',
        'Cognitive Pilot',
        'HiRUS',
        '–¢–∞–∫—Å–ù–µ—Ç',
        '–¢–∞—Ç–Ω–µ—Ñ—Ç—å –¶–∏—Ñ—Ä–æ–≤—ã–µ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
        '–°–æ—Ä–∞–º–∏—Ç—Å—É –õ–∞–±—Å',
        '–ò–Ω—Ñ–æ–º–∞—Ç–∏–∫–∞',
        'Sirin',
        'red_mad_robot',
        'RoadAR',
        'Radius-etl.ru',
        'Headmade',
        'FIX',
        '–ú–µ–º–æ—Ä–∏–∞–ª',
        'Lemon Technologies Group',
        'Qummy',
        '–ö–æ–Ω—Ç—É—Ä',
'Digital Biz Factory'
    ]
    text = doc.text
    for company in companies:
        if company in text:
            return company

    text_lower = text.lower()
    for company in companies:
        if company.lower() in text_lower:
            return company

    return None


def extract_location(doc):
    locations = ['–ö–∞–∑–∞–Ω—å', '–ú–æ—Å–∫–≤–∞', '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '–ê–ª–º–∞—Ç—ã', '–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥', '–ò–Ω–Ω–æ–ø–æ–ª–∏—Å', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä', '–ß–µ–ª—è–±–∏–Ω—Å–∫', '–ü–µ—Ä–º—å', '–ò–∂–µ–≤—Å–∫', '–£–ª—å—è–Ω–æ–≤—Å–∫']
    text = doc.text
    for location in locations:
        if location in text:
            return location

    text_lower = text.lower()
    for location in locations:
        if location.lower() in text_lower:
            return location

    return None


def extract_salary(doc):
    salary_patterns = [
        r"(?:¬£|\$|‚Ç¨)(\d{1,3}(?:,\d{3})*)(?:\s*-\s*(\d{1,3}(?:,\d{3})*))?\s*(K|k)?",
        r"(?:–∑/–ø|–∑–∞—Ä–ø–ª–∞—Ç–∞).*?(\d[\d\s]+)\s*(?:-|–¥–æ)\s*(\d[\d\s]+)\s*([$‚Ç¨‚ÇΩ—Ä—É–±]|\w+)",
        r"(\d[\d\s]+)\s*(?:-|–¥–æ)\s*(\d[\d\s]+)\s*(—Ä—É–±|‚ÇΩ|USD|\$)"
    ]

    for pattern in salary_patterns:
        matches = re.finditer(pattern, doc.text)
        for match in matches:
            # Clean and convert numbers
            salary_from = int(match.group(1).replace(" ", "").replace(",", "")) if match.group(1) else None
            salary_to = int(match.group(2).replace(" ", "").replace(",", "")) if match.group(2) and match.group(
                2).isdigit() else None

            return {
                "salary_from": salary_from,
                "salary_to": salary_to,
                "salary_currency": match.group(3),
                "salary_mode": "monthly" if "–º–µ—Å—è—Ü" in doc.text else None
            }
    return {}


def extract_work_form(doc):
    """Extract work form using pre-built matcher"""
    if doc.lang_ == "en":
        matches = work_form_matcher_en(doc)
    else:  # Assume Russian
        matches = work_form_matcher_ru(doc)

    for match_id, start, end in matches:
        return doc[start:end].text
    return None

def extract_expirience(doc):
    expirience_keywords = ["–æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã", "–æ–ø—ã—Ç", "expirience"]
    for token in doc:
        if token.text.lower() in expirience_keywords:
            # Get surrounding text (3 words before and after)
            start = max(0, token.i)
            end = min(len(doc), token.i + 5)
            return re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø0-9\s]', '', doc[start:end].text.capitalize())
    return None


def parse_vacancy(text):
    # Process with both pipelines
    text = text.replace("*", "")
    doc_ru = nlp_ru(text)
    # For Russian text, English processing isn't needed
    result = {
        "is_vacancy": is_vacancy(doc_ru),
        "job_title": extract_job_title(doc_ru),
        "company": extract_company(doc_ru),
        "location": extract_location(doc_ru),
        "experience": extract_expirience(doc_ru),
        "description": " ".join([sent.text for sent in doc_ru.sents][:3]),
        "work_form": extract_work_form(doc_ru),
    }

    # Add salary data if found
    salary_data = extract_salary(doc_ru) or {
                "salary_from": None,
                "salary_to": None,
                "salary_currency": None,
                "salary_mode": None
            }
    result.update(salary_data)

    return result


#–¢–µ—Å—Ç
if __name__ == '__main__':
    text = """üì£ **–°—Ç–∞–∂—ë—Ä Data Science –≤ Ozon Tech**

–ü—Ä–æ–µ–∫—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ–Ω–∞ –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –≤–æ –≤—Ä–µ–º—è —Ä–∞—Å–ø—Ä–æ–¥–∞–∂

**üìå –ó–∞–¥–∞—á–∏: **
- —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –æ–±—É—á–µ–Ω–∏–µ CV-–º–æ–¥–µ–ª–µ–π, –ø—Ä–æ–¥—É–º—ã–≤–∞–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑, –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
- —Ä–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ - —Å–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π
- –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—Å—è —Å –º–µ—Ç–æ–¥–∞–º–∏ –¥–µ–ø–ª–æ—è –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–æ–¥
- –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –±–∏–∑–Ω–µ—Å-–∑–∞–∫–∞–∑—á–∏–∫–∞–º–∏ –∏ –ø–µ—Ä–µ–≤–æ–¥ –±–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –≤ –ø–ª–æ—Å–∫–æ—Å—Ç—å ML

–ó–∞—Ä–ø–ª–∞—Ç–∞ –æ—Ç 0 –¥–æ 10 —Ä—É–±–ª–µ–π

–æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã 10 –≤–µ—á–Ω–æ—Å—Ç–µ–π. –ö—Å—Ç–∞—Ç–∏ –∏–¥–∏ –Ω–∞—Ö—É–π
[üëâüèº **–ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ –æ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–µ**](https://job.ozon.ru/vacancy/121749776?__rr=1&abt_att=1)"""

    print(parse_vacancy(text))